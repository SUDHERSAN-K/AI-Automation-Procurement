{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "090f8f47",
      "metadata": {
        "id": "090f8f47"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b1191bd5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1191bd5",
        "outputId": "2d5c2c6e-131f-446c-e15d-bc2de4d2f254"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting llm_connect\n",
            "  Downloading llm_connect-2.0.0-py3-none-any.whl (12 kB)\n",
            "Collecting torch~=2.1.0\n",
            "  Downloading torch-2.1.2-cp39-none-macosx_11_0_arm64.whl (59.6 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 59.6 MB 4.5 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting accelerate\n",
            "  Downloading accelerate-1.6.0-py3-none-any.whl (354 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 354 kB 2.6 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting click==8.1.7\n",
            "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 97 kB 2.9 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting setuptools~=68.2.0\n",
            "  Downloading setuptools-68.2.2-py3-none-any.whl (807 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 807 kB 2.8 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: transformers in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from llm_connect) (4.49.0)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105.0 MB 4.1 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: filelock in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from torch~=2.1.0->llm_connect) (3.18.0)\n",
            "Requirement already satisfied: jinja2 in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from torch~=2.1.0->llm_connect) (3.1.5)\n",
            "Requirement already satisfied: sympy in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from torch~=2.1.0->llm_connect) (1.13.1)\n",
            "Requirement already satisfied: networkx in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from torch~=2.1.0->llm_connect) (3.2.1)\n",
            "Requirement already satisfied: fsspec in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from torch~=2.1.0->llm_connect) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from torch~=2.1.0->llm_connect) (4.12.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from accelerate->llm_connect) (0.5.3)\n",
            "Requirement already satisfied: pyyaml in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from accelerate->llm_connect) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from accelerate->llm_connect) (0.29.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from accelerate->llm_connect) (24.1)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from accelerate->llm_connect) (1.26.4)\n",
            "Requirement already satisfied: psutil in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from accelerate->llm_connect) (6.0.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.21.0->accelerate->llm_connect) (4.67.1)\n",
            "Requirement already satisfied: requests in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.21.0->accelerate->llm_connect) (2.32.3)\n",
            "Requirement already satisfied: scipy in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from bitsandbytes->llm_connect) (1.13.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from jinja2->torch~=2.1.0->llm_connect) (3.0.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from requests->huggingface-hub>=0.21.0->accelerate->llm_connect) (3.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from requests->huggingface-hub>=0.21.0->accelerate->llm_connect) (3.4.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from requests->huggingface-hub>=0.21.0->accelerate->llm_connect) (2025.1.31)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from requests->huggingface-hub>=0.21.0->accelerate->llm_connect) (2.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from sympy->torch~=2.1.0->llm_connect) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from transformers->llm_connect) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from transformers->llm_connect) (0.21.1)\n",
            "Installing collected packages: torch, setuptools, colorama, click, bitsandbytes, accelerate, llm-connect\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0\n",
            "    Uninstalling torch-2.6.0:\n",
            "      Successfully uninstalled torch-2.6.0\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.1.8\n",
            "    Uninstalling click-8.1.8:\n",
            "      Successfully uninstalled click-8.1.8\n",
            "Successfully installed accelerate-1.6.0 bitsandbytes-0.42.0 click-8.1.7 colorama-0.4.6 llm-connect-2.0.0 setuptools-68.2.2 torch-2.1.2\n",
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
            "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install llm_connect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9b562415",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b562415",
        "outputId": "60155d15-a7d1-4c1e-fcdf-c3a7417a1000"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: torch\n",
            "Version: 2.1.2\n",
            "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
            "Home-page: https://pytorch.org/\n",
            "Author: PyTorch Team\n",
            "Author-email: packages@pytorch.org\n",
            "License: BSD-3\n",
            "Location: /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages\n",
            "Requires: filelock, fsspec, typing-extensions, sympy, jinja2, networkx\n",
            "Required-by: sentence-transformers, llm_connect, accelerate\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip show torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5607b949",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5607b949",
        "outputId": "0e93ccd3-f4c5-40b7-ff5d-a65e45af2934"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: torch in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (2.1.2)\n",
            "Requirement already satisfied: jinja2 in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: sympy in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: fsspec in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: filelock in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: networkx in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from sympy->torch) (1.3.0)\n",
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
            "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "cfbafc38",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfbafc38",
        "outputId": "58ded039-649b-4ae9-e612-ffb895897516"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: torch==2.1.2 in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (2.1.2)\n",
            "Requirement already satisfied: sympy in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from torch==2.1.2) (1.13.1)\n",
            "Requirement already satisfied: networkx in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from torch==2.1.2) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from torch==2.1.2) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from torch==2.1.2) (2025.3.0)\n",
            "Requirement already satisfied: filelock in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from torch==2.1.2) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from torch==2.1.2) (4.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from jinja2->torch==2.1.2) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from sympy->torch==2.1.2) (1.3.0)\n",
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
            "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install torch==2.1.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d726e070",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d726e070",
        "outputId": "89b4549e-4b3b-4a0f-d216-93d20a2db0da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting faker\n",
            "  Downloading faker-37.1.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.9 MB 2.4 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: tzdata in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from faker) (2024.2)\n",
            "Installing collected packages: faker\n",
            "Successfully installed faker-37.1.0\n",
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
            "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install faker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c42e96e8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c42e96e8",
        "outputId": "c9ce01bf-c101-4a5c-878d-737a8f301217"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting fpdf\n",
            "  Downloading fpdf-1.7.2.tar.gz (39 kB)\n",
            "Building wheels for collected packages: fpdf\n",
            "  Building wheel for fpdf (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40704 sha256=60cb31d9a30e6f011ca57a0b52faf3c5a94c03896926fb7888203b518a3029cf\n",
            "  Stored in directory: /Users/nujoumunus/Library/Caches/pip/wheels/44/35/8b/86ce00cec7e4d13c5f189680ae0fa82f919bedc066c2cddae9\n",
            "Successfully built fpdf\n",
            "Installing collected packages: fpdf\n",
            "Successfully installed fpdf-1.7.2\n",
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
            "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install fpdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "e399b599",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting rapidfuzz\n",
            "  Downloading rapidfuzz-3.13.0-cp39-cp39-macosx_11_0_arm64.whl (1.5 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.5 MB 2.2 MB/s eta 0:00:01\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz\n",
            "Successfully installed rapidfuzz-3.13.0\n",
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
            "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install rapidfuzz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "bcd06c7b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcd06c7b",
        "outputId": "f9d475cf-11cc-4652-ea5e-c533e48c702f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Excel file saved: generated_files/BOM_1.xlsx\n",
            "PDF file saved: generated_files/BOM_1.pdf\n",
            "Excel file saved: generated_files/BOM_2.xlsx\n",
            "PDF file saved: generated_files/BOM_2.pdf\n",
            "Excel file saved: generated_files/BOM_3.xlsx\n",
            "PDF file saved: generated_files/BOM_3.pdf\n",
            "Excel file saved: generated_files/BOM_4.xlsx\n",
            "PDF file saved: generated_files/BOM_4.pdf\n",
            "Excel file saved: generated_files/BOM_5.xlsx\n",
            "PDF file saved: generated_files/BOM_5.pdf\n",
            "Generated Excel and PDF BOMs saved in generated_files/\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "from faker import Faker\n",
        "from fpdf import FPDF\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Initialize Faker\n",
        "tool = Faker()\n",
        "\n",
        "# Sample company names and project names\n",
        "supplier_names = [\"Zenith Engineering\", \"Pinnacle Systems\", \"Vertex Constructors\", \"Nexus EPC\"]\n",
        "project_names = [\"Project Apollo\", \"Sunrise Refinery\", \"Delta Wind Farm\", \"Oceanic Bridge\", \"Metro Line 9\"]\n",
        "\n",
        "# U.S.-specific units of measure and material categories\n",
        "units_of_measure = [\"Each\", \"Feet\", \"Pound\", \"Gallon\"]\n",
        "material_categories = [\"Piping\", \"Electrical\", \"Civil\", \"Mechanical\", \"Structural\"]\n",
        "\n",
        "# Directory to save files\n",
        "output_dir = \"generated_files\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Generate a single fake Engineering BOM and save as Excel\n",
        "def generate_fake_bom_excel(company, project, filename, is_bechtel=True, num_items=10):\n",
        "    # Generate fake BOM data\n",
        "    data = []\n",
        "    for _ in range(num_items):\n",
        "        item_id = f\"ITM-{random.randint(1000,9999)}\"\n",
        "        desc = random.choice([\n",
        "            \"Steel Beam\", \"Electric Motor\", \"PVC Pipe\", \"Hydraulic Pump\",\n",
        "            \"Control Valve\", \"Sensor\", \"Cable Reel\", \"Safety Helmet\",\n",
        "            \"Heat Exchanger\", \"Solar Panel\"\n",
        "        ])\n",
        "        qty = random.randint(1, 500)\n",
        "        uom = random.choice(units_of_measure)\n",
        "        spec = random.choice([\n",
        "            \"A36 Steel\", \"IP65 Rated\", \"Schedule 40\", \"316 Stainless Steel\",\n",
        "            \"VFD Compatible\", \"High Voltage 480V\"\n",
        "        ])\n",
        "        material_cat = random.choice(material_categories)\n",
        "        drawing_ref = f\"DRW-{random.randint(100,999)}-{random.choice(['PIP','ELC','CIV','MEC','STR'])}-{random.randint(1000,9999)}\"\n",
        "        delivery = tool.date_between(start_date='+10d', end_date='+60d').strftime('%Y-%m-%d')\n",
        "        data.append([\n",
        "            item_id, desc, qty, uom, spec, material_cat, drawing_ref, delivery\n",
        "        ])\n",
        "\n",
        "    # Create DataFrame\n",
        "    columns = [\"Item ID\", \"Description\", \"Quantity\", \"Unit of Measure\", \"Specification\", \"Material Category\", \"Drawing Reference\", \"Required Delivery Date\"]\n",
        "    df = pd.DataFrame(data, columns=columns)\n",
        "\n",
        "    # Save as Excel\n",
        "    excel_path = os.path.join(output_dir, filename + \".xlsx\")\n",
        "    df.to_excel(excel_path, index=False)\n",
        "    print(f\"Excel file saved: {excel_path}\")\n",
        "\n",
        "    # Also save as PDF\n",
        "    pdf = FPDF()\n",
        "    pdf.add_page()\n",
        "    pdf.set_font(\"Arial\", size=12)\n",
        "\n",
        "    # Header\n",
        "    pdf.cell(0, 10, f\"{company} - {project}\", ln=True, align='C')\n",
        "    pdf.cell(0, 10, \"Engineering Bill of Materials (EBOM)\", ln=True, align='C')\n",
        "    pdf.ln(10)\n",
        "\n",
        "    # Table headers\n",
        "    pdf.set_font(\"Arial\", 'B', 9)\n",
        "    col_widths = [20, 40, 15, 20, 40, 30, 40, 30]\n",
        "    headers = columns\n",
        "    for i, header in enumerate(headers):\n",
        "        pdf.cell(col_widths[i], 10, header, border=1)\n",
        "    pdf.ln()\n",
        "\n",
        "    # Table rows with slight random font variation\n",
        "    for _, row in df.iterrows():\n",
        "        pdf.set_font(\"Arial\", '', random.choice([8,9,10]))\n",
        "        for i, item in enumerate(row):\n",
        "            pdf.cell(col_widths[i], 8, str(item), border=1)\n",
        "        pdf.ln()\n",
        "\n",
        "    pdf_path = os.path.join(output_dir, filename + \".pdf\")\n",
        "    pdf.output(pdf_path)\n",
        "    print(f\"PDF file saved: {pdf_path}\")\n",
        "\n",
        "# Generate multiple Excel and PDF BOMs\n",
        "def generate_multiple_boms(num_boms=5):\n",
        "    for i in range(num_boms):\n",
        "        if random.random() < 0.7:\n",
        "            company = \"Bechtel Solutions\"\n",
        "            is_bechtel = True\n",
        "        else:\n",
        "            company = random.choice(supplier_names)\n",
        "            is_bechtel = False\n",
        "\n",
        "        project = random.choice(project_names)\n",
        "        filename = f\"BOM_{i+1}\"\n",
        "        generate_fake_bom_excel(company, project, filename, is_bechtel=is_bechtel)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    generate_multiple_boms(num_boms=5)\n",
        "    print(f\"Generated Excel and PDF BOMs saved in {output_dir}/\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vBd1yB7oxsYZ",
      "metadata": {
        "id": "vBd1yB7oxsYZ"
      },
      "source": [
        "## STEP 2: Use all BOM Excel Files to .dxf\n",
        "\n",
        "Here's what the .dxf file contains based on your earlier script logic:\n",
        "\n",
        "  1. Entities in the DXF file: 1 LWPOLYLINE (rectangle)\n",
        "  \n",
        "  2. Represents the visual placeholder (20x10 unit rectangle).\n",
        "     Coordinates: [(0, 0), (0, 10), (20, 10), (20, 0), (0, 0)]\n",
        "     \n",
        "  3. 4 TEXT entities, placed at different vertical positions:\n",
        "           A. \"ITM-1720\" (Item ID) at position (1, 11)\n",
        "           B. \"Control Valve\" (Description) at position (1, 9)\n",
        "           C. \"Spec: 316 Stainless Steel\" at position (1, 7)\n",
        "           D. \"Qty: 300\" at position (1, 5)\n",
        "           E. Each with varying height attributes (font size)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "WaCjPgpPyTEC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaCjPgpPyTEC",
        "outputId": "e49e2220-96f3-4ab2-83e9-f733d24f06dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting ezdxf\n",
            "  Downloading ezdxf-1.4.1-cp39-cp39-macosx_11_0_arm64.whl (2.9 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.9 MB 2.1 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: numpy in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from ezdxf) (1.26.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.1 in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from ezdxf) (3.2.1)\n",
            "Requirement already satisfied: fonttools in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from ezdxf) (4.55.8)\n",
            "Requirement already satisfied: typing_extensions>=4.6.0 in /Users/nujoumunus/Library/Python/3.9/lib/python/site-packages (from ezdxf) (4.12.2)\n",
            "Installing collected packages: ezdxf\n",
            "Successfully installed ezdxf-1.4.1\n",
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
            "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install ezdxf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "7d57a2d8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d57a2d8",
        "outputId": "daa5ff09-d472-4515-c502-f0d63d9c4aff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All .dxf files saved to: generated_dxf\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import ezdxf\n",
        "import os\n",
        "\n",
        "def generate_dxf_from_bom_folder(bom_folder=\"generated_files\", output_dir=\"generated_dxf\"):\n",
        "    \"\"\"\n",
        "    Converts all Excel BOM files in the given folder to .dxf files\n",
        "    using relative paths. Each item in each BOM becomes a labeled drawing.\n",
        "\n",
        "    Parameters:\n",
        "    - bom_folder: relative path to the folder containing .xlsx BOM files\n",
        "    - output_dir: relative path to the output folder for .dxf files\n",
        "    \"\"\"\n",
        "    # Get absolute paths from relative\n",
        "    bom_folder = os.path.abspath(bom_folder)\n",
        "    output_dir = os.path.abspath(output_dir)\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    for bom_file in os.listdir(bom_folder):\n",
        "        if bom_file.endswith(\".xlsx\"):\n",
        "            bom_path = os.path.join(bom_folder, bom_file)\n",
        "            df = pd.read_excel(bom_path)\n",
        "\n",
        "            for index, row in df.iterrows():\n",
        "                item_id = row.get(\"Item ID\", f\"ITEM_{index}\")\n",
        "                desc = row.get(\"Description\", \"N/A\")\n",
        "                spec = row.get(\"Specification\", \"N/A\")\n",
        "                qty = row.get(\"Quantity\", \"N/A\")\n",
        "\n",
        "                doc = ezdxf.new(dxfversion='R2010')\n",
        "                msp = doc.modelspace()\n",
        "\n",
        "                # Drawing: rectangle + annotated text\n",
        "                msp.add_lwpolyline([(0, 0), (0, 10), (20, 10), (20, 0), (0, 0)], close=True)\n",
        "                msp.add_text(f\"{item_id}\", dxfattribs={\"height\": 2}).dxf.insert = (1, 11)\n",
        "                msp.add_text(f\"{desc}\", dxfattribs={\"height\": 1}).dxf.insert = (1, 9)\n",
        "                msp.add_text(f\"Spec: {spec}\", dxfattribs={\"height\": 1}).dxf.insert = (1, 7)\n",
        "                msp.add_text(f\"Qty: {qty}\", dxfattribs={\"height\": 1}).dxf.insert = (1, 5)\n",
        "\n",
        "                base_name = os.path.splitext(bom_file)[0]\n",
        "                file_name = f\"{base_name}_{item_id}.dxf\"\n",
        "                dxf_path = os.path.join(output_dir, file_name)\n",
        "                doc.saveas(dxf_path)\n",
        "\n",
        "    print(f\"All .dxf files saved to: {os.path.relpath(output_dir)}\")\n",
        "\n",
        "# Example usage (runs relative to your current working directory):\n",
        "generate_dxf_from_bom_folder()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7Ba7femA3acA",
      "metadata": {
        "id": "7Ba7femA3acA"
      },
      "source": [
        "## STEP 3: Create Historical BOM File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "XgXbDzb42Xkw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgXbDzb42Xkw",
        "outputId": "6e57f5bf-3b9e-43fa-a444-644c8944f8d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ 10 simulated historical BOMs created in both Excel and PDF formats in 'historical_data/'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "from faker import Faker\n",
        "from fpdf import FPDF\n",
        "\n",
        "# Initialize Faker\n",
        "faker = Faker()\n",
        "\n",
        "# Output folder\n",
        "output_folder = \"historical_data\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Sample values\n",
        "descriptions = [\n",
        "    \"Steel Beam\", \"Electric Motor\", \"PVC Pipe\", \"Hydraulic Pump\",\n",
        "    \"Control Valve\", \"Sensor\", \"Cable Reel\", \"Safety Helmet\",\n",
        "    \"Heat Exchanger\", \"Solar Panel\"\n",
        "]\n",
        "specs = [\n",
        "    \"A36 Steel\", \"IP65 Rated\", \"Schedule 40\", \"316 Stainless Steel\",\n",
        "    \"VFD Compatible\", \"High Voltage 480V\"\n",
        "]\n",
        "units = [\"Each\", \"Feet\", \"Pound\", \"Gallon\"]\n",
        "categories = [\"Piping\", \"Electrical\", \"Civil\", \"Mechanical\", \"Structural\"]\n",
        "suppliers = [\"FlowMax Inc.\", \"Valvex Corp.\", \"IronWorks Ltd.\", \"GreenVolt Systems\", \"HydroMech Supplies\"]\n",
        "\n",
        "# Generate both Excel and PDF\n",
        "def generate_historical_bom(file_name_base, num_items=10):\n",
        "    data = []\n",
        "    for _ in range(num_items):\n",
        "        item_id = f\"ITM-{random.randint(1000, 9999)}\"\n",
        "        desc = random.choice(descriptions)\n",
        "        spec = random.choice(specs)\n",
        "        qty = random.randint(10, 500)\n",
        "        unit = random.choice(units)\n",
        "        cat = random.choice(categories)\n",
        "        drawing = f\"DRW-{random.randint(100, 999)}-{random.choice(['PIP','ELC','CIV','MEC','STR'])}-{random.randint(1000, 9999)}\"\n",
        "        delivery = faker.date_between(start_date='-2y', end_date='today').strftime('%Y-%m-%d')\n",
        "        supplier = random.choice(suppliers)\n",
        "        data.append([item_id, desc, qty, unit, spec, cat, drawing, delivery, supplier])\n",
        "\n",
        "    columns = [\n",
        "        \"Item ID\", \"Description\", \"Quantity\", \"Unit of Measure\", \"Specification\",\n",
        "        \"Material Category\", \"Drawing Reference\", \"Required Delivery Date\", \"Supplier\"\n",
        "    ]\n",
        "    df = pd.DataFrame(data, columns=columns)\n",
        "\n",
        "    # Save Excel\n",
        "    excel_path = os.path.join(output_folder, f\"{file_name_base}.xlsx\")\n",
        "    df.to_excel(excel_path, index=False)\n",
        "\n",
        "    # Generate PDF\n",
        "    pdf = FPDF()\n",
        "    pdf.add_page()\n",
        "    pdf.set_font(\"Arial\", size=10)\n",
        "    pdf.cell(0, 10, f\"Engineering BOM - {file_name_base}\", ln=True, align='C')\n",
        "    pdf.ln(5)\n",
        "\n",
        "    # Table headers\n",
        "    pdf.set_font(\"Arial\", 'B', 8)\n",
        "    col_widths = [20, 30, 12, 18, 35, 20, 35, 25, 35]\n",
        "    for i, header in enumerate(columns):\n",
        "        pdf.cell(col_widths[i], 6, header, border=1)\n",
        "    pdf.ln()\n",
        "\n",
        "    # Table rows\n",
        "    pdf.set_font(\"Arial\", '', 7)\n",
        "    for _, row in df.iterrows():\n",
        "        for i, item in enumerate(row):\n",
        "            pdf.cell(col_widths[i], 6, str(item), border=1)\n",
        "        pdf.ln()\n",
        "\n",
        "    pdf_path = os.path.join(output_folder, f\"{file_name_base}.pdf\")\n",
        "    pdf.output(pdf_path)\n",
        "\n",
        "# Generate 10 historical BOMs\n",
        "for i in range(1, 11):\n",
        "    file_base = f\"Old_BOM_{i}\"\n",
        "    generate_historical_bom(file_base)\n",
        "\n",
        "print(\"‚úÖ 10 simulated historical BOMs created in both Excel and PDF formats in 'historical_data/'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "On27NORf48Nr",
      "metadata": {
        "id": "On27NORf48Nr"
      },
      "source": [
        "# STEP 4: Build the supplier/specification recommendation engine, and link each suggestion to its .dxf drawing.\n",
        "\n",
        "## üîç Matching Logic: Weighted Similarity Strategy\n",
        "\n",
        "We compute similarity using the following **weighted combination** of fields:\n",
        "\n",
        "| **Field**             | **Weight** | **Notes**                                                               |\n",
        "|-----------------------|------------|-------------------------------------------------------------------------|\n",
        "| `Description`         | 0.4        | Fuzzy match of item name (e.g., \"Control Valve\", \"Sensor\")             |\n",
        "| `Specification`       | 0.3        | Exact or partial match (e.g., \"316 Stainless Steel\")                   |\n",
        "| `Material Category`   | 0.2        | Must match exactly or be within related categories                     |\n",
        "| `Unit of Measure`     | 0.1        | Should match directly (e.g., \"Each\" vs \"Feet\")                         |\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ Output Recommendation Includes:\n",
        "- üè∑ **Suggested Supplier**\n",
        "- üõ† **Matched Specification**\n",
        "- üìÅ **Source BOM** (from historical data)\n",
        "- üìê **DXF File Path**  \n",
        "  Example: `generated_dxf/BOM_1_ITM-1234.dxf`\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WF-ScQdd8ymF",
      "metadata": {
        "id": "WF-ScQdd8ymF"
      },
      "source": [
        "## Multi-BOM Matching with DXF Linking - METHOD 1 (Using Difflib)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dYFy3lz85U-A",
      "metadata": {
        "id": "dYFy3lz85U-A"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "4q9Ge90e5AYp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4q9Ge90e5AYp",
        "outputId": "2e405d09-47b7-418c-9fe7-6cfb5d861792"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Recommendations saved to BOM_Supplier_Recommendations.xlsx\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "# -----------------------------\n",
        "# Load Historical BOMs\n",
        "# -----------------------------\n",
        "def load_historical_bom_data(folder_path=\"historical_data\"):\n",
        "    all_data = []\n",
        "    for file in os.listdir(folder_path):\n",
        "        if file.endswith(\".xlsx\"):\n",
        "            df = pd.read_excel(os.path.join(folder_path, file))\n",
        "            df[\"Source Historical BOM\"] = os.path.splitext(file)[0]\n",
        "            all_data.append(df)\n",
        "    return pd.concat(all_data, ignore_index=True)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Load a Single New BOM\n",
        "# -----------------------------\n",
        "def load_new_bom(file_path):\n",
        "    return pd.read_excel(file_path)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Weighted Similarity Function\n",
        "# -----------------------------\n",
        "def similarity(a, b):\n",
        "    return SequenceMatcher(None, str(a).lower(), str(b).lower()).ratio()\n",
        "\n",
        "\n",
        "def match_item(new_row, historical_df):\n",
        "    best_match = None\n",
        "    highest_score = 0\n",
        "\n",
        "    for _, old_row in historical_df.iterrows():\n",
        "        score = (\n",
        "            0.4 * similarity(new_row[\"Description\"], old_row[\"Description\"]) +\n",
        "            0.3 * similarity(new_row[\"Specification\"], old_row[\"Specification\"]) +\n",
        "            0.2 * (1.0 if new_row[\"Material Category\"] == old_row[\"Material Category\"] else 0.0) +\n",
        "            0.1 * (1.0 if new_row[\"Unit of Measure\"] == old_row[\"Unit of Measure\"] else 0.0)\n",
        "        )\n",
        "        if score > highest_score:\n",
        "            highest_score = score\n",
        "            best_match = old_row\n",
        "\n",
        "    return {\n",
        "        \"Suggested Supplier\": best_match[\"Supplier\"] if best_match is not None else None,\n",
        "        \"Suggested Spec\": best_match[\"Specification\"] if best_match is not None else None,\n",
        "        \"Match Score\": round(highest_score, 2),\n",
        "        \"Matched Item ID\": best_match[\"Item ID\"] if best_match is not None else None,\n",
        "        \"Source Historical BOM\": best_match[\"Source Historical BOM\"] if best_match is not None else None,\n",
        "    }\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Generate Recommendations for All New BOM Files\n",
        "# -----------------------------\n",
        "def generate_recommendations_for_all_boms(new_bom_folder=\"generated_files\", dxf_folder=\"generated_dxf\"):\n",
        "    historical_df = load_historical_bom_data()\n",
        "    all_recommendations = []\n",
        "\n",
        "    for bom_file in os.listdir(new_bom_folder):\n",
        "        if bom_file.endswith(\".xlsx\"):\n",
        "            new_bom_path = os.path.join(new_bom_folder, bom_file)\n",
        "            new_bom_df = load_new_bom(new_bom_path)\n",
        "\n",
        "            for _, new_row in new_bom_df.iterrows():\n",
        "                result = match_item(new_row, historical_df)\n",
        "                item_id = new_row[\"Item ID\"]\n",
        "\n",
        "                # Find matching DXF file\n",
        "                dxf_file = next((f for f in os.listdir(dxf_folder)\n",
        "                                 if f.endswith(\".dxf\") and item_id in f), None)\n",
        "                dxf_path = os.path.join(dxf_folder, dxf_file) if dxf_file else None\n",
        "\n",
        "                all_recommendations.append({\n",
        "                    \"Source New BOM\": bom_file,\n",
        "                    \"Item ID\": item_id,\n",
        "                    \"Description\": new_row[\"Description\"],\n",
        "                    \"Suggested Supplier\": result[\"Suggested Supplier\"],\n",
        "                    \"Suggested Spec\": result[\"Suggested Spec\"],\n",
        "                    \"Match Score\": result[\"Match Score\"],\n",
        "                    \"Matched Item ID\": result[\"Matched Item ID\"],\n",
        "                    \"Source Historical BOM\": result[\"Source Historical BOM\"],\n",
        "                    \"DXF File Path\": dxf_path\n",
        "                })\n",
        "\n",
        "    return pd.DataFrame(all_recommendations)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Run the Full Pipeline\n",
        "# -----------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    final_recommendations = generate_recommendations_for_all_boms(\n",
        "        new_bom_folder=\"generated_files\",     # Folder with BOM_1.xlsx ... BOM_5.xlsx\n",
        "        dxf_folder=\"generated_dxf\"            # Folder with DXF files\n",
        "    )\n",
        "\n",
        "    # Save or display\n",
        "    final_recommendations.to_excel(\"BOM_Supplier_Recommendations.xlsx\", index=False)\n",
        "    print(\"‚úÖ Recommendations saved to BOM_Supplier_Recommendations.xlsx\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DgCrAh2-_dWR",
      "metadata": {
        "id": "DgCrAh2-_dWR"
      },
      "source": [
        "## METHOD 2: RAPIDFUZZ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "zdMFOdk5AZlw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdMFOdk5AZlw",
        "outputId": "7fffee8d-385d-44ad-dc81-6355258f6733"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: command not found: pip\n"
          ]
        }
      ],
      "source": [
        "!pip install rapidfuzz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "jbldsSVM_iHh",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbldsSVM_iHh",
        "outputId": "046673ac-0e60-47da-9453-9a3f5a71a149"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Recommendations saved to All_BOM_Supplier_Recommendations.xlsx\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from rapidfuzz import fuzz\n",
        "\n",
        "# -----------------------------\n",
        "# Load Historical BOMs\n",
        "# -----------------------------\n",
        "def load_historical_bom_data(folder_path=\"historical_data\"):\n",
        "    all_data = []\n",
        "    for file in os.listdir(folder_path):\n",
        "        if file.endswith(\".xlsx\"):\n",
        "            df = pd.read_excel(os.path.join(folder_path, file))\n",
        "            df[\"Source Historical BOM\"] = os.path.splitext(file)[0]\n",
        "            all_data.append(df)\n",
        "    return pd.concat(all_data, ignore_index=True)\n",
        "\n",
        "# -----------------------------\n",
        "# Match Function Using RapidFuzz\n",
        "# -----------------------------\n",
        "def match_item_with_rapidfuzz(new_row, historical_df):\n",
        "    \"\"\"\n",
        "    Matches a new BOM item against historical BOM dataset using token-based\n",
        "    fuzzy string matching from `rapidfuzz`.\n",
        "\n",
        "    Fields:\n",
        "    - Description (0.4 weight): token sort fuzzy match\n",
        "    - Specification (0.3): direct fuzzy match\n",
        "    - Material Category (0.2): exact match\n",
        "    - Unit of Measure (0.1): exact match\n",
        "    \"\"\"\n",
        "    best_match = None\n",
        "    highest_score = 0\n",
        "\n",
        "    for _, old_row in historical_df.iterrows():\n",
        "        score = (\n",
        "            0.4 * (fuzz.token_sort_ratio(new_row[\"Description\"], old_row[\"Description\"]) / 100) +\n",
        "            0.3 * (fuzz.ratio(new_row[\"Specification\"], old_row[\"Specification\"]) / 100) +\n",
        "            0.2 * (1.0 if new_row[\"Material Category\"] == old_row[\"Material Category\"] else 0.0) +\n",
        "            0.1 * (1.0 if new_row[\"Unit of Measure\"] == old_row[\"Unit of Measure\"] else 0.0)\n",
        "        )\n",
        "\n",
        "        if score > highest_score:\n",
        "            highest_score = score\n",
        "            best_match = old_row\n",
        "\n",
        "    return {\n",
        "        \"Suggested Supplier\": best_match[\"Supplier\"] if best_match is not None else None,\n",
        "        \"Suggested Spec\": best_match[\"Specification\"] if best_match is not None else None,\n",
        "        \"Match Score\": round(highest_score, 2),\n",
        "        \"Matched Item ID\": best_match[\"Item ID\"] if best_match is not None else None,\n",
        "        \"Source Historical BOM\": best_match[\"Source Historical BOM\"] if best_match is not None else None,\n",
        "    }\n",
        "\n",
        "# -----------------------------\n",
        "# Run Recommendations for BOM_1 to BOM_5\n",
        "# -----------------------------\n",
        "def generate_recommendations_for_all_boms(new_bom_folder=\"generated_files\", dxf_folder=\"generated_dxf\"):\n",
        "    historical_df = load_historical_bom_data()\n",
        "    all_recommendations = []\n",
        "\n",
        "    for bom_file in os.listdir(new_bom_folder):\n",
        "        if bom_file.endswith(\".xlsx\") and bom_file.startswith(\"BOM_\"):  # Only BOM_1 to BOM_5\n",
        "            new_bom_path = os.path.join(new_bom_folder, bom_file)\n",
        "            new_bom_df = pd.read_excel(new_bom_path)\n",
        "\n",
        "            for _, new_row in new_bom_df.iterrows():\n",
        "                result = match_item_with_rapidfuzz(new_row, historical_df)\n",
        "                item_id = new_row[\"Item ID\"]\n",
        "\n",
        "                # Match corresponding DXF file\n",
        "                dxf_file = next((f for f in os.listdir(dxf_folder)\n",
        "                                 if f.endswith(\".dxf\") and item_id in f), None)\n",
        "                dxf_path = os.path.join(dxf_folder, dxf_file) if dxf_file else None\n",
        "\n",
        "                all_recommendations.append({\n",
        "                    \"Source New BOM\": bom_file,\n",
        "                    \"Item ID\": item_id,\n",
        "                    \"Description\": new_row[\"Description\"],\n",
        "                    \"Suggested Supplier\": result[\"Suggested Supplier\"],\n",
        "                    \"Suggested Spec\": result[\"Suggested Spec\"],\n",
        "                    \"Match Score\": result[\"Match Score\"],\n",
        "                    \"Matched Item ID\": result[\"Matched Item ID\"],\n",
        "                    \"Source Historical BOM\": result[\"Source Historical BOM\"],\n",
        "                    \"DXF File Path\": dxf_path\n",
        "                })\n",
        "\n",
        "    return pd.DataFrame(all_recommendations)\n",
        "\n",
        "# -----------------------------\n",
        "# Main Execution\n",
        "# -----------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    final_df = generate_recommendations_for_all_boms(\n",
        "        new_bom_folder=\"generated_files\",\n",
        "        dxf_folder=\"generated_dxf\"\n",
        "    )\n",
        "    final_df.to_excel(\"BOM_Supplier_Recommendations_Rapidfuzz.xlsx\", index=False)\n",
        "    print(\"‚úÖ Recommendations saved to All_BOM_Supplier_Recommendations.xlsx\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KL_zrWOkAIye",
      "metadata": {
        "id": "KL_zrWOkAIye"
      },
      "source": [
        "## ‚öîÔ∏è `rapidfuzz` vs `difflib` for BOM Matching\n",
        "\n",
        "| Feature                     | `difflib.SequenceMatcher`                         | `rapidfuzz` (e.g., `token_sort_ratio`)               |\n",
        "|-----------------------------|---------------------------------------------------|------------------------------------------------------|\n",
        "| üîÅ **Word Order Awareness** | ‚ùå `\"Valve Control\"` ‚â† `\"Control Valve\"`          | ‚úÖ Handles reordered words intelligently              |\n",
        "| ‚úèÔ∏è **Typo Tolerance**       | ‚ùå Minimal ‚Äî not fuzzy in a real-world sense       | ‚úÖ Robust to minor typos and formatting differences   |\n",
        "| ‚ö° **Speed**                | ‚ùå Slower, especially with many comparisons        | ‚úÖ Much faster and scalable for larger datasets       |\n",
        "| üìä **Matching Quality**     | üü° Works on character-level diff                  | ‚úÖ Token-based logic gives **more accurate scores**   |\n",
        "| üì¶ **Installation**         | ‚úÖ Built-in (no install needed)                   | ‚ùóRequires: `pip install rapidfuzz`                   |\n",
        "| ü§ñ **String Intelligence**  | ‚ùå Blind to synonyms, abbreviations, or structure | üü° Slightly better ‚Äî but still not semantic           |\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ Summary:\n",
        "> **`rapidfuzz` is strongly preferred** for BOM item matching because:\n",
        "> - It handles word order\n",
        "> - It tolerates minor text differences\n",
        "> - It is faster and more accurate\n",
        "> - It better mimics how humans interpret similarity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "bb40001b",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "\n",
        "def get_data(sheet_name: str) -> list:\n",
        "    \"\"\"\n",
        "    Fetch data  from a Google Sheet.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    sheet_name : str\n",
        "        Name of the Google Sheet tab.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    list of dict\n",
        "        Each row in the sheet as a dictionary.\n",
        "    \"\"\"\n",
        "    # scope = [\n",
        "    # \"https://spreadsheets.google.com/feeds\", \n",
        "    # \"https://www.googleapis.com/auth/drive\"\n",
        "    # ]\n",
        "    # creds = ServiceAccountCredentials.from_json_keyfile_name(\"credentials.json\", scope)\n",
        "    # gs_client = gspread.authorize(creds)  \n",
        "    # spreadsheet = gs_client.open_by_url(\"https://docs.google.com/spreadsheets/d/1ioqw78lMaf1tpFrU4QmcShZgl79bn6iqljnF3Uu8krU/edit?gid=244310017#gid=244310017/edit#gid=0\")\n",
        "    # worksheet = spreadsheet.worksheet(sheet_name)\n",
        "    # data = worksheet.get_all_records()\n",
        "    data = pd.read_excel('generated_files/BOM_1.xlsx')\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "FxiNRwsEAMRh",
      "metadata": {
        "id": "FxiNRwsEAMRh"
      },
      "outputs": [],
      "source": [
        "def get_item_list_from_sheet(sheet_name: str = \"items\") -> list:\n",
        "    raw_data = get_data(sheet_name)\n",
        "    return [row[\"Item Name\"] for row in raw_data if \"Item Name\" in row and row[\"Item Name\"].strip()]\n",
        "items = get_item_list_from_sheet(\"items\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "db649cb0",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_item_data_from_sheet(sheet_name: str = \"items\") -> list:\n",
        "    \"\"\"\n",
        "    Fetches full item rows from the Google Sheet tab 'items'.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    list of dicts:\n",
        "        Each dict contains item metadata like:\n",
        "        Item Name, Specification, Quantity, Unit of Measure, Delivery Date, Drawing Ref\n",
        "    \"\"\"\n",
        "    return get_data(sheet_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d020179e",
      "metadata": {},
      "outputs": [],
      "source": [
        "item_data = get_item_data_from_sheet(\"items\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "fe4f7ee9",
      "metadata": {},
      "outputs": [],
      "source": [
        "def vendor_selector_template(user_input):\n",
        "    return f\"\"\"\n",
        "You are a procurement assistant tasked with selecting the most suitable vendor for each item listed.\n",
        "\n",
        "You have access to vendor profiles that include:\n",
        "\n",
        "Past history with our company\n",
        "\n",
        "Relevant certifications\n",
        "\n",
        "Area of expertise\n",
        "\n",
        "Average lead time (in days)\n",
        "\n",
        "Your task:\n",
        "For each item, select the single best vendor based on the above criteria and the relevance of the vendor's profile to the item‚Äôs requirements.\n",
        "\n",
        "Output Format:\n",
        "Return the results in a markdown table with the following columns:\n",
        "\n",
        "Item\n",
        "\n",
        "Suggested Vendor\n",
        "\n",
        "Reason for Selection (1‚Äì2 bullet points per row)\n",
        "\n",
        "Additional Instructions:\n",
        "\n",
        "If the same vendor is suitable for multiple items, list those item names together in the same row under the ‚ÄúItem‚Äù column (comma-separated).\n",
        "\n",
        "Do not include any introductory or closing text.\n",
        "\n",
        "Add a title above the table:\n",
        "\"Vendors suggestion based on Bechtel database\"\" \n",
        "\n",
        "Item to source: {user_input['item']}\n",
        "\n",
        "Vendor list:\n",
        "{user_input['vendor_data']}\n",
        "\"\"\"\n",
        "\n",
        "def suggest_vendors_llm(item_name: list, llm: str = \"llama\") -> str:\n",
        "    vendor_data = get_data(\"vendors\")\n",
        "\n",
        "    prompt_input = {\n",
        "        \"item\": item_name,\n",
        "        \"vendor_data\": vendor_data\n",
        "    }\n",
        "\n",
        "    return get_response(\n",
        "        input=prompt_input,\n",
        "        template=vendor_selector_template,\n",
        "        role=\"You are a procurement assistant helping select vendors for a specific item.\",\n",
        "        temperature=0.4,\n",
        "        max_tokens=400,\n",
        "        md=True,\n",
        "        llm=llm\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "4eddba01",
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'get_response' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msuggest_vendors_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[8], line 50\u001b[0m, in \u001b[0;36msuggest_vendors_llm\u001b[0;34m(item_name, llm)\u001b[0m\n\u001b[1;32m     43\u001b[0m vendor_data \u001b[38;5;241m=\u001b[39m get_data(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvendors\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     45\u001b[0m prompt_input \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitem\u001b[39m\u001b[38;5;124m\"\u001b[39m: item_name,\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvendor_data\u001b[39m\u001b[38;5;124m\"\u001b[39m: vendor_data\n\u001b[1;32m     48\u001b[0m }\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_response\u001b[49m(\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mprompt_input,\n\u001b[1;32m     52\u001b[0m     template\u001b[38;5;241m=\u001b[39mvendor_selector_template,\n\u001b[1;32m     53\u001b[0m     role\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a procurement assistant helping select vendors for a specific item.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     54\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4\u001b[39m,\n\u001b[1;32m     55\u001b[0m     max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m400\u001b[39m,\n\u001b[1;32m     56\u001b[0m     md\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     57\u001b[0m     llm\u001b[38;5;241m=\u001b[39mllm\n\u001b[1;32m     58\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_response' is not defined"
          ]
        }
      ],
      "source": [
        "suggest_vendors_llm(items)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "9c3d614f",
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "string indices must be integers",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 75\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Generate RFQ per vendor\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m vendor, item_names \u001b[38;5;129;01min\u001b[39;00m suggested_vendor_map\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 75\u001b[0m     item_subset \u001b[38;5;241m=\u001b[39m [item \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m item_data_all \u001b[38;5;28;01mif\u001b[39;00m item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mItem Name\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m item_names]\n\u001b[1;32m     77\u001b[0m     rfq_text \u001b[38;5;241m=\u001b[39m get_response(\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     79\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproject_info\u001b[39m\u001b[38;5;124m\"\u001b[39m: project_info,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m         md\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     87\u001b[0m     )\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- RFQ for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvendor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[0;32mIn[11], line 75\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Generate RFQ per vendor\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m vendor, item_names \u001b[38;5;129;01min\u001b[39;00m suggested_vendor_map\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 75\u001b[0m     item_subset \u001b[38;5;241m=\u001b[39m [item \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m item_data_all \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mItem Name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;129;01min\u001b[39;00m item_names]\n\u001b[1;32m     77\u001b[0m     rfq_text \u001b[38;5;241m=\u001b[39m get_response(\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     79\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproject_info\u001b[39m\u001b[38;5;124m\"\u001b[39m: project_info,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m         md\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     87\u001b[0m     )\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- RFQ for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvendor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
          ]
        }
      ],
      "source": [
        "#### RFQ Formatter Tool\n",
        "def generate_rfq_document(project_info: dict, item_data: list, vendor_name: str = None) -> str:\n",
        "    \"\"\"\n",
        "    Generate a vendor-ready RFQ document in plain text/markdown.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    project_info : dict\n",
        "        Contains project name, delivery address, submission deadline, and buyer contact info.\n",
        "\n",
        "    item_data : list of dict\n",
        "        List of items to be included in the RFQ. Each item should have fields:\n",
        "        - Item Name, Specification, Quantity, Unit of Measure, Delivery Date, Drawing Ref\n",
        "\n",
        "    vendor_name : str, optional\n",
        "        If a specific vendor is being addressed, include their name in the greeting.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    str\n",
        "        A formatted RFQ text block ready to be emailed or saved.\n",
        "    \"\"\"\n",
        "\n",
        "def rfq_formatter_prompt(inputs):\n",
        "    vendor_name = inputs.get(\"vendor_name\", \"Vendor\")\n",
        "    project = inputs[\"project_info\"]\n",
        "    items = inputs[\"item_data\"]\n",
        "\n",
        "    item_lines = \"\\n\".join(\n",
        "        [f\"- {item['Item Name']}: {item['Specification']} | Qty: {item['Quantity']} {item['Unit of Measure']} | Delivery by: {item['Delivery Date']} | Ref: {item['Drawing Ref']}\"\n",
        "         for item in items]\n",
        "    )\n",
        "\n",
        "    return f\"\"\"\n",
        "You are a procurement assistant tasked with creating a vendor-ready RFQ.\n",
        "Generate a professional, well-structured RFQ in markdown format with the following structure:\n",
        "\n",
        "Greeting:\n",
        "\"Dear {vendor_name},\"\n",
        "\n",
        "Body:\n",
        "- Brief project description using: {project['Project Name']}, located in {project['Location']}\n",
        "- Include buyer contact info: {project['Engineering Lead']} (procurement@doha-metro.com)\n",
        "- List the items requested as bullet points\n",
        "\n",
        "Closing:\n",
        "- State deadline for quotation submission: 1 week from today\n",
        "- Ask the vendor to confirm receipt and reach out with questions\n",
        "\n",
        "Item List:\n",
        "{item_lines}\n",
        "\n",
        "Only return the RFQ body. No commentary or explanation.\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "\n",
        "# Load the JSON file\n",
        "with open(\"project_context.json\", \"r\") as file:\n",
        "    project_info = json.load(file)\n",
        "\n",
        "project_info\n",
        "suggested_vendor_map = {\n",
        "    \"Alpha Solutions 2\": [\"Carbon Steel Flange\", \"Gate Valve\", \"Earthing Strip\", \"Fire Rated Door\"],\n",
        "    \"Trans Partners 13\": [\"HVAC Duct Connector\"],\n",
        "    \"Metro Industries 1\": [\"Cable Tray\", \"Signal Conduit\", \"Control Cable\"],\n",
        "    \"Steel Solutions 16\": [\"Structural Steel Beam\"],\n",
        "    \"Metro Industries 9\": [\"Lighting Fixture - Tunnel Type\"]\n",
        "}\n",
        "\n",
        "item_data_all = get_item_data_from_sheet(\"items\")\n",
        "\n",
        "# Generate RFQ per vendor\n",
        "for vendor, item_names in suggested_vendor_map.items():\n",
        "    item_subset = [item for item in item_data_all if item[\"Item Name\"] in item_names]\n",
        "\n",
        "    rfq_text = get_response(\n",
        "        input={\n",
        "            \"project_info\": project_info,\n",
        "            \"item_data\": item_subset,\n",
        "            \"vendor_name\": vendor\n",
        "        },\n",
        "        template=rfq_formatter_prompt,\n",
        "        role=\"You are a helpful assistant drafting procurement RFQs.\",\n",
        "        llm=\"llama\",\n",
        "        md=True\n",
        "    )\n",
        "\n",
        "    print(f\"\\n--- RFQ for {vendor} ---\\n\")\n",
        "    print(rfq_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8aa7cad",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
